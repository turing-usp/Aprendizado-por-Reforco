{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial - Gym\n",
    "\n",
    "## Índice\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## O que é o Gym?\n",
    "O **Gym** é um conjunto de ferramentas que ajudam no desenvolvimento e na comparação de algoritmos de aprendizado por reforço. A biblioteca é basicamente um conjunto de *environments*, ou ambientes de teste que o usuário pode utilizar pra testar seus algoritmos. Vale notar que esses ambientes têm uma interface compartilhada, desta forma torna-se possível escrever algoritmos gerais.\n",
    "<center><img src=\"https://gym.openai.com/assets/dist/nav/nav-logo-dark-e5f2a4965e.svg\" width=\"400\"/></center>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Como usar o Gym?\n",
    "\n",
    "Com o Gym, é possível testar e comparar algoritmos de aprendizado por reforço através dos diversos *environments* oferecidos pela biblioteca e as ferramentas de metrificação por ela implementadas, que possibilitam analisar o desempenho dos algoritmos utilizados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instalação\n",
    "\n",
    "A instalação do Gym pode ser realizada de duas formas diferentes, primeiramente através do pip (Python 3.5+):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pip install gym"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ou, caso queira modificar alguma funcionalidade ou adicionar ambientes, é possível buildar a biblioteca direto do source:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "git clone https://github.com/openai/gym\n",
    "cd gym\n",
    "pip install -e .[all]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tenha em mente que a instrução acima não vai rodar do jeito que deveria num notebook, mas se seu interesse é em buildar a biblioteca provavelmente já sabia disso."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ambientes\n",
    "\n",
    "O principal atrativo do Gym são os diversos ambientes oferecidos prontos para usar. Mas afinal, o que é um **ambiente**? O **ambiente** é o espaço que representa o nosso problema: o mundo com o qual o agente pode interagir, e no qual ele deve se basear para a tomada de decisões. Um exemplo seria numa partida de xadrez, em que o ambiente seria o conjunto de peças no tabuleiro.\n",
    "\n",
    "Pronto, agora você já sabe o que é um ambiente, mas como eu crio um usando o gym?\n",
    "\n",
    "Os ambientes do Gym possuem uma série de métodos simples que usamos para manipular e analisar eles. Os principais para essa etapa do tutorial são esses:\n",
    "<center>\n",
    "<br>\n",
    "\n",
    "| Método               | Funcionalidade                                          |\n",
    "| :------------------- |:------------------------------------------------------- |\n",
    "| `make()` | Cria o ambiente |\n",
    "| `reset()`              | Inicializa o ambiente e recebe a observação inicial     |\n",
    "| `step(action)`         | Executa uma ação e recebe a observação e a recompensa   |\n",
    "| `render()`             | Renderiza o ambiente                                    |\n",
    "| `close()`              | Fecha o ambiente                                        |\n",
    "\n",
    "<br>\n",
    "</center>\n",
    "\n",
    "Com isto em mente, vamos fazer algo aparecer na tela:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import gym\n",
    "env = gym.make('MountainCar-v0')        # Cria um ambiente, experimente coisas diferentes, como por exemplo 'CartPole-v0'\n",
    "env.reset()                             # Inicializa o ambiente              \n",
    "for _ in range(1000):                   # Durante 1000 timesteps\n",
    "    env.render()                        # Renderiza (mostra) o ambiente\n",
    "    env.step(env.action_space.sample()) # Escolhe uma ação aleatória\n",
    "env.close()                             # Fecha o ambiente"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se tudo correu bem, você deve ter visto algo como isso na sua tela:\n",
    "\n",
    "<center><img src=\"\" width=\"400\"/></center>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observações\n",
    "Porém, como você deve ter notado, mexer aleatoriamente pra esquerda e pra direita não é bem um **aprendizado**, então é de se esperar que eventualmente seria interessante ensinar alguma coisa pro agente, porém como fazer isso?\n",
    "\n",
    "Primeiro, vale explicar o retorno da função `env.step()`, na verdade, ela retorna quatro valores que possibilitam implementar algoritmos de aprendizado por reforço, estes sendo:\n",
    "<center>\n",
    "\n",
    "|Nome|Tipo|Descrição|\n",
    "|-|-|-|\n",
    "|`observation`|objeto|Um objeto especifico por ambiente que representa a observação do ambiente.|\n",
    "|`reward`|float|Quantidade de recompensa alcançada pela última ação. A escala varia com o ambiente|\n",
    "|`done`|boolean|Flag que indica se é hora de chamar o `reset()`. Indica que o episódio terminou.|\n",
    "|`info`|dict|Informações diagnósticas úteis para debugar. Geralmente é bom pra estudar,<br> mas o seu agente não usa isso pra aprender|\n",
    "\n",
    "</center>\n",
    "\n",
    "Perceba que trata-se de uma implementação do ciclo de agente-ambiente, onde a cada timestep o agente escolhe uma ação e o ambiente retorna uma observação e uma recompensa.\n",
    "\n",
    "<center><img src=\"https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg\" width=\"300\"/></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i_episode in range(20):                                         # Para 20 episódios\n",
    "    observation = env.reset()                   \n",
    "    for t in range(100):                                            \n",
    "        env.render()\n",
    "        print(observation)                                          # Mostra as observações\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Fim do episodio em {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A saída por enquanto é apenas um tanto de texto e números, note também que a mensagem que seria mostrada com o Done nunca é mostrada. Isso acontece por causa do ambiente escolhido, onde o done só acontece quando o carrinho sai da tela, o que muito provavelmente não aconteceu."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Espaços\n",
    "\n",
    "Nos exemplos anteriores nós pegavamos as ações aleatóriamente do espaço de ações do ambiente, mas o que são essas ações? No gym, todo ambiente vem com um `action_space` e um `observation_space`. Esses atributos têm o tipo `Space` e descrevem o formato das ações. Por exemplo, se quisermos ver o tipo de `action_space` ou do `observation_space` do nosso ambiente, podemos executar:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discrete(3)\n",
      "Box(-1.2000000476837158, 0.6000000238418579, (2,), float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O espaço `Discrete` permite a escolha de um número fixo de valores não negativos que representam as ações, neste caso, 0, 1 e 2, uma vez que o carrinho pode ir para a esquerda, direita e freiar. Já o espaço `Box` representa uma caixa n-dimensional, desta forma, observações válidas são uma array de 2 números (Na saída acima: `Box(..., ..., (2,), ...)`)\n",
    "\n",
    "Também é possível descobrir os limites da `Box`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(env.observation_space.high)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.6  0.07]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(env.observation_space.low)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-1.2  -0.07]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir dessas informações, podemos concluir que os limites superiores e inferiores referentes ao ambiente, no caso o máximo e mínimo em X e Y do carrinho."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusões\n",
    "\n",
    "Essencialmente, este é o Gym e um de seus ambientes. Se além de aprender a utilizar a biblioteca e criar um ambiente, você também tem interesse em entender como utilizar um algoritmo de aprendizado por reforço, dê uma olhada no nosso tutorial de **[Stable Baselines]([https://github.com/DLR-RM/stable-baselines3](https://github.com/turing-usp/Aprendizado-por-Reforco/tree/main/Bibliotecas/Stable%20Baselines))**. \n",
    "\n",
    "Aproveite e dê uma olhada nos [outros ambientes disponíveis na biblioteca]([https://gym.openai.com/envs/#classic_control]), eles não se limitam apenas nesses exemplos simples, a openAI disponibiliza desde portes de jogos de atari até modelos de ambientes tridimensionais."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}