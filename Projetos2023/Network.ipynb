{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datagram:\n",
    "    def __init__(self, source: int, destination: int):\n",
    "        self.source = source\n",
    "        self.destination = destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    def __init__(self, size: int):\n",
    "        self.queue = []\n",
    "        self.size = size\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.queue) == 0\n",
    "    \n",
    "    def enqueue(self, datagram: Datagram):\n",
    "        if len(self.queue) < self.size:\n",
    "            self.queue.append(datagram)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.isEmpty():\n",
    "            return self.queue.pop(0)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event:\n",
    "    def __init__(self, delay: int, destination: int, datagram: Datagram):\n",
    "        self.delay = delay\n",
    "        self.destination = destination\n",
    "        self.datagram = datagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router: #roteador\n",
    "    \n",
    "    def __init__(self, address: int, size: int):\n",
    "        self.address = address\n",
    "        self.adjacents = {}\n",
    "        self.size = size\n",
    "        self.queue = Queue(self.size)\n",
    "\n",
    "    #método mapear\n",
    "    def link(self, router, delay: int):\n",
    "        \"\"\"\n",
    "        Ele deve ter o mesmo retorno do método mapear da TabelaDeRepasse: true se o\n",
    "        mapeamento foi feito ou false caso o endereço já tenha um mapeamento ou a tabela esteja cheia.\n",
    "        \"\"\"\n",
    "        if router.address not in self.adjacents:\n",
    "            self.adjacents[router.address] = (router, delay)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def receive(self, datagram: Datagram):\n",
    "        if datagram.destination != self.address:\n",
    "            \n",
    "            if self.queue.size == self.size:\n",
    "                print(f'Fila em {self.address} estourou ')\n",
    "            else:\n",
    "                self.queue.queue(datagram)\n",
    "            \n",
    "        else:\n",
    "            del datagram\n",
    "\n",
    "    def process(self, action: int): \n",
    "        if not self.queue.is_empty():\n",
    "            datagram = self.queue.dequeue()\n",
    "            if datagram.destination == self.address:\n",
    "                del datagram\n",
    "                return \n",
    "            else: \n",
    "                return Event(self.adjacents[action][1], action, datagram)\n",
    "                    \n",
    "        else:\n",
    "            return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, size: int, gen_prob: float, max_data: int, generate: bool=True) -> None:\n",
    "        \"\"\"\n",
    "        @param size: size of the network\n",
    "        @param gen_prob: probability of generating one packet\n",
    "        @param max_data: max number of datagrams that can be generated in one instant\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.quantity = 0\n",
    "        self.routers = {}\n",
    "        self.gen_prob = gen_prob\n",
    "        self.max_data = max_data\n",
    "        self.generate = generate\n",
    "\n",
    "    def add_router(self, router: Router):\n",
    "        if self.quantity < self.size:\n",
    "            if router.address not in self.routers:\n",
    "                self.routers[router.address] = router\n",
    "                self.quantity += 1\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def generate_random_data(self):\n",
    "        if self.generate:\n",
    "            for _ in range(self.max_data):\n",
    "                if np.random.random() < self.gen_prob:\n",
    "                    sender = random.choice([self.routers.keys()])\n",
    "                    # !!!!! Assumindo que a rede seja toda conectada !!!!! \"\n",
    "                    receiver = random.choice([self.routers.keys()])\n",
    "                    datagram = Datagram(sender, receiver)\n",
    "                    self.routers[sender].receive(datagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    def __init__(self, inicial_instant: int, network: Network, size: int):\n",
    "        self.instant = inicial_instant\n",
    "        self.network = network\n",
    "        self.size = size\n",
    "        self.events = []\n",
    "    \n",
    "    def process(self, action: list[int]):\n",
    "        for event in self.events:\n",
    "            if event.delay == 0:\n",
    "                event.destination.receive(event.datagram)\n",
    "        self.events = [event for event in self.events if event.delay != 0]\n",
    "        for event in self.events:\n",
    "            event.delay -= 1\n",
    "        for router in self.network.routers:            \n",
    "            event = router.process(action[router.address])\n",
    "            if event is not None:\n",
    "                self.events.append(event)\n",
    "        self.network.generate_random_data()\n",
    "        self.instant += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, network, scheduler):\n",
    "        self.network = network\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def get_all_states(self):\n",
    "        ...\n",
    "    \n",
    "    def get_state(self):\n",
    "        events_state = []\n",
    "        for event in self.scheduler.events:\n",
    "            event_state = (event.instant, event.destination, event.datagram.destination)\n",
    "            events_state.append(event_state)\n",
    "\n",
    "        routers_state = []\n",
    "        for router in self.network.routers:\n",
    "            router_state = []\n",
    "            datagrams_state = []\n",
    "            for datagram in router.datagrams:\n",
    "                datagrams_state.append(datagram.destination)\n",
    "            router_state.append(datagrams_state)\n",
    "            for adjacent in router.adjacents:\n",
    "                queue_state = []\n",
    "                for datagram in router.adjacents[adjacent][0].queue:\n",
    "                    queue_state.append(datagram.destination)\n",
    "                router_state.append(queue_state)\n",
    "            routers_state.append(router_state)\n",
    "            \n",
    "        return (events_state, routers_state)\n",
    "    \n",
    "    def take_action(self, action):\n",
    "        reward = 0\n",
    "        for router in self.network.routers:\n",
    "            reward -= len(router.datagrams)\n",
    "        reward -= len(self.scheduler.events)\n",
    "        self.scheduler.process(action)\n",
    "        new_state = self.get_state()\n",
    "        return reward, new_state\n",
    "    \n",
    "    def start(self, state = None): \n",
    "        ...\n",
    "\n",
    "    def possible_actions(self, current=True):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cria Rede Genérica\n",
    "![rede 1](./img/rede1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = Network(4, 1.0, 1)\n",
    "\n",
    "r1 = Router(1,2)\n",
    "r2 = Router(2,2)\n",
    "r3 = Router(3,2)\n",
    "r4 = Router(4,2)\n",
    "\n",
    "r1.link(r2, 2)\n",
    "r1.link(r3, 5)\n",
    "\n",
    "r2.link(r1, 2)\n",
    "r2.link(r4, 3)\n",
    "\n",
    "r3.link(r1, 2)\n",
    "r3.link(r4, 4)\n",
    "\n",
    "r4.link(r2, 2)\n",
    "r4.link(r3, 5)\n",
    "\n",
    "network.add_router(r1)\n",
    "network.add_router(r2)\n",
    "network.add_router(r3)\n",
    "network.add_router(r4)\n",
    "\n",
    "scheduler = Scheduler(0, network, 5)\n",
    "\n",
    "environment = Environment(network, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs: Se não for ter criação de evento AGENDADO, o método schedule() parece pouco útil, podemos inserir um novo datagrama diretamente em datagrams do router de origem \n",
    "\n",
    "Onde está deletando os eventos?\n",
    "\n",
    "Ordem dos elementos no estados não deve importar ex: [1, 2] = [2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Q_Learning:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.policy = {}\n",
    "        self.values = {}\n",
    "\n",
    "    def q_learning(self, alpha, epsilon, time_steps, gama):\n",
    "        self.initialize() #Initialize value table \n",
    "\n",
    "        self.env.start()\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            state = self.env.get_state()\n",
    "            \n",
    "            if random.random() >= epsilon:\n",
    "                action = max(self.values[state], key = self.values[state].get)\n",
    "            else:\n",
    "                action = random.choice(list(self.values[state].keys())) #ou usar o possible actions\n",
    "\n",
    "            reward, next_state = self.env.take_action(action)\n",
    "            self.values[state][action] += alpha*(reward + gama*max(self.values[next_state].values()) - self.values[state][action])\n",
    "        \n",
    "    def initialize(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StateActionArray:\n",
    "    def __init__(self, env: Environment):\n",
    "        ...\n",
    "    def get(self, state, action):\n",
    "        ...\n",
    "    def set(self, state, action, value):\n",
    "        ...\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, env:Environment, eps: float=0):\n",
    "        ...\n",
    "    def get(self, state):\n",
    "        ...\n",
    "    def set(self, state, action):\n",
    "        ...\n",
    "        \n",
    "def sarsa(env: Environment, returns: StateActionArray, policy: Policy, gamma: float, alpha: float):\n",
    "    \n",
    "    env.reset()\n",
    "    state = env.get_state()\n",
    "    action = policy.get(state)\n",
    "    while True:\n",
    "        reward, next_state = env.take_action(action)\n",
    "        next_action = policy.get(next_state)\n",
    "        current_return = returns.get(state, action)\n",
    "        \n",
    "        next_return = 0\n",
    "        if not env.terminal():\n",
    "            next_return = returns.get(next_state, next_action)\n",
    "\n",
    "        new_return = current_return + alpha * (gamma * next_return - current_return + reward)\n",
    "        returns.set(state, action, new_return)\n",
    "\n",
    "        actions = env.possible_actions()\n",
    "        values = [returns.get(state, act) for act in actions]\n",
    "        policy.set(state, actions[np.argmax(values)])\n",
    "\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "        if env.terminal():\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Episode:\n",
    "    def __init__(self, env : Environment, initialState, initialAction, policy):\n",
    "        self.env = env\n",
    "        env.start(initialState)\n",
    "        self.initialState = initialState\n",
    "        self.initialAction = initialAction\n",
    "        self.pairs = []\n",
    "        self.rewards = []\n",
    "        self.policy = policy\n",
    "        self.steps = 0\n",
    "\n",
    "    def genEpisode(self):\n",
    "        state = self.initialState\n",
    "        action = self.initialAction\n",
    "        while True:\n",
    "            self.pairs.append((state, action))\n",
    "            reward, state = self.env.takeAction(action)\n",
    "            self.rewards.append(reward)\n",
    "            self.steps += 1\n",
    "            if (state == -1 or self.steps == 400):\n",
    "                self.steps = len(self.rewards)\n",
    "                return\n",
    "            action = self.policy[state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_MC:\n",
    "    def __init__(self, env: Environment):\n",
    "        self.env = env\n",
    "        self.pairs = {}\n",
    "        for state in env.get_all_states():\n",
    "            for action in env.possible_actions(state):\n",
    "                self.pairs.append((state, action))\n",
    "        self.Q_values = {pair : [0, 0] for pair in self.pairs}\n",
    "        self.policy = {state : np.choice([self.pairs[(state, action)] for action in env.possible_actions(state)])}\n",
    "\n",
    "    def initialize(self):\n",
    "        for pair in self.pairs:\n",
    "            self.Q_values[pair] = [0, 0]\n",
    "        for state in self.env.get_all_states():\n",
    "            self.policy[state] = np.choice([self.pairs[(state, action)] for action in self.env.possible_actions(state)])\n",
    "    \n",
    "    def MCES(self, numEpisodes, gamma):\n",
    "        for _ in range(numEpisodes):\n",
    "            start_pair = random.choice(self.pairs)\n",
    "            episode = Episode(self.env, start_pair[0], start_pair[1], self.policy)\n",
    "            episode.genEpisode()\n",
    "            g = 0\n",
    "            for step in range(episode.steps - 1, -1, -1):\n",
    "                g = gamma * g + episode.rewards[step]\n",
    "                pair = episode.pairs[step]\n",
    "                if (pair not in episode.pairs[0:step]):\n",
    "                    self.Q_values[pair][0] = (self.Q_values[pair][0] * self.Q_values[pair][1] + g) / (self.Q_values[pair][1] + 1)\n",
    "                    self.Q_values[pair][1] += 1\n",
    "                    self.policy[pair[0]] = self.actions[pair[0]][np.argmax([self.Q_values[(pair[0], action)][0] for action in self.actions[pair[0]]])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
