{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Datagram:\n",
    "    def __init__(self, source: int, destination: int):\n",
    "        self.source = source\n",
    "        self.destination = destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    def __init__(self, size: int):\n",
    "        self.queue = []\n",
    "        self.size = size\n",
    "        self.length = 0\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self.length == 0\n",
    "    \n",
    "    def enqueue(self, datagram: Datagram):\n",
    "        if self.length < self.size:\n",
    "            self.queue.append(datagram)\n",
    "            self.length += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def dequeue(self):\n",
    "        if not self.is_empty():\n",
    "            self.length -= 1\n",
    "            return self.queue.pop(0)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Event:\n",
    "    def __init__(self, delay: int, destination: int, datagram: Datagram):\n",
    "        self.delay = delay\n",
    "        self.destination = destination\n",
    "        self.datagram = datagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Router: #roteador\n",
    "    \n",
    "    def __init__(self, address: int, size: int):\n",
    "        self.address = address\n",
    "        self.adjacents = {}\n",
    "        self.size = size\n",
    "        self.queue = Queue(self.size)\n",
    "    \n",
    "    def start(self, destinations):\n",
    "        self.queue = Queue(self.size)\n",
    "        for destination in destinations:\n",
    "            if self.queue.enqueue(Datagram(-1, destination)) == False:\n",
    "                raise Exception(f\"start do roteador {self.address} excedeu capacidade máxima\")\n",
    "\n",
    "    def receive(self, datagram: Datagram):\n",
    "        if datagram.destination != self.address:\n",
    "            \n",
    "            if self.queue.length == self.size:\n",
    "                return -100\n",
    "            else:\n",
    "                self.queue.enqueue(datagram)\n",
    "                return 0\n",
    "            \n",
    "        else:\n",
    "            del datagram\n",
    "            return 10\n",
    "\n",
    "    def process(self, action: int): \n",
    "        if not self.queue.is_empty():\n",
    "            datagram = self.queue.dequeue()\n",
    "            if datagram.destination == self.address:\n",
    "                del datagram\n",
    "            else:\n",
    "                return Event(self.adjacents[action][1], action, datagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "----------------\n",
      "reward = 0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "----------------\n",
      "reward = 10\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "----------------\n",
      "8\n",
      "4\n",
      "1\n",
      "----------------\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "----------------\n",
      "reward = 0\n",
      "reward = 0\n",
      "reward = -100\n",
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "r0 = Router(0, 10)\n",
    "r1 = Router(1, 2)\n",
    "r0.start([1, 2, 1, 1])\n",
    "for d in r0.queue.queue:\n",
    "    print(d.destination)\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f'reward = {r0.receive(Datagram(-1, 3))}')\n",
    "for d in r0.queue.queue:\n",
    "    print(d.destination)\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f'reward = {r0.receive(Datagram(-1, 0))}')\n",
    "for d in r0.queue.queue:\n",
    "    print(d.destination)\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "r0.adjacents[4] = [r1, 8]\n",
    "event = r0.process(4)\n",
    "print(event.delay)\n",
    "print(event.destination)\n",
    "print(event.datagram.destination)\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "for d in r0.queue.queue:\n",
    "    print(d.destination)\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "print(f'reward = {r1.receive(Datagram(-1, 0))}')\n",
    "print(f'reward = {r1.receive(Datagram(-1, 5))}')\n",
    "print(f'reward = {r1.receive(Datagram(-1, 7))}')\n",
    "for d in r1.queue.queue:\n",
    "    print(d.destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, size: int, gen_prob: float, max_data: int, generate: bool=True) -> None:\n",
    "        \"\"\"\n",
    "        @param size: size of the network\n",
    "        @param gen_prob: probability of generating one packet\n",
    "        @param max_data: max number of datagrams that can be generated in one instant\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.quantity = 0\n",
    "        self.routers = {}\n",
    "        self.gen_prob = gen_prob\n",
    "        self.max_data = max_data\n",
    "        self.generate = generate\n",
    "\n",
    "    def add_router(self, size):\n",
    "        if self.quantity < self.size:\n",
    "            self.quantity += 1\n",
    "            self.routers[self.quantity] = Router(self.quantity, size)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    #método mapear\n",
    "    def link(self, address_1, address_2, delay):\n",
    "        \"\"\"\n",
    "        Ele deve ter o mesmo retorno do método mapear da TabelaDeRepasse: true se o\n",
    "        mapeamento foi feito ou false caso o endereço já tenha um mapeamento ou a tabela esteja cheia.\n",
    "        \"\"\"\n",
    "        if address_1 in self.routers and address_2 in self.routers:\n",
    "            if address_1 not in self.routers[address_2].adjacents and address_2 not in self.routers[address_1].adjacents:\n",
    "                self.routers[address_1].adjacents[address_2] = (self.routers[address_2], delay)\n",
    "                self.routers[address_2].adjacents[address_1] = (self.routers[address_1], delay)\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def start(self, routers_state):\n",
    "        for address in range(1, len(routers_state) + 1):\n",
    "            self.routers[address].start(routers_state[address - 1])\n",
    "    \n",
    "    def generate_random_data(self):\n",
    "        if self.generate:\n",
    "            for _ in range(self.max_data):\n",
    "                if np.random.random() < self.gen_prob:\n",
    "                    sender = random.choice(list(self.routers.keys()))\n",
    "                    # !!!!! Assumindo que a rede seja toda conectada !!!!! \"\n",
    "                    receiver = random.choice([address for address in list(self.routers.keys()) if address != sender])\n",
    "                    # print((sender, receiver)) # não apagar: útil para testes\n",
    "                    datagram = Datagram(sender, receiver)\n",
    "                    self.routers[sender].receive(datagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "10\n",
      "-\n",
      "2\n",
      "2\n",
      "3\n",
      "-\n",
      "3\n",
      "3\n",
      "6\n",
      "-\n",
      "----------------\n",
      "True\n",
      "True\n",
      "False\n",
      "{2: (<__main__.Router object at 0x000001DF6A373FA0>, 8), 3: (<__main__.Router object at 0x000001DF6A371F60>, 40)}\n",
      "[2, 3]\n",
      "{1: (<__main__.Router object at 0x000001DF6A371E70>, 8)}\n",
      "[1]\n",
      "{1: (<__main__.Router object at 0x000001DF6A371E70>, 40)}\n",
      "[1]\n",
      "----------------\n",
      "address: 1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "-\n",
      "address: 2\n",
      "-\n",
      "address: 3\n",
      "2\n",
      "1\n",
      "1\n",
      "-\n",
      "----------------\n",
      "(3, 1)\n",
      "(2, 1)\n",
      "(1, 3)\n",
      "address: 1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "-\n",
      "address: 2\n",
      "1\n",
      "-\n",
      "address: 3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "network = Network(10, 0.9, 3, True)\n",
    "network.add_router(10)\n",
    "network.add_router(3)\n",
    "network.add_router(6)\n",
    "for router in network.routers:\n",
    "    print(router)\n",
    "    print(network.routers[router].address)\n",
    "    print(network.routers[router].size)\n",
    "    print(\"-\")\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "print(network.link(1, 2, 8))\n",
    "print(network.link(1, 3, 40))\n",
    "print(network.link(1, 3, 60))\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "    print(network.routers[i].adjacents)\n",
    "    print([network.routers[i].adjacents[j][0].address for j in network.routers[i].adjacents])\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "network.start([[2, 3, 2, 2], [], [2, 1, 1]])\n",
    "for router in network.routers.values():\n",
    "    print(\"address:\", router.address)\n",
    "    for d in router.queue.queue:\n",
    "        print(d.destination)\n",
    "    print(\"-\")\n",
    "\n",
    "print(\"----------------\")\n",
    "\n",
    "network.generate_random_data()\n",
    "for router in network.routers.values():\n",
    "    print(\"address:\", router.address)\n",
    "    for d in router.queue.queue:\n",
    "        print(d.destination)\n",
    "    print(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    def __init__(self, network: Network):\n",
    "        self.network = network\n",
    "        self.events = []\n",
    "    \n",
    "    def start(self, events):\n",
    "        self.events = []\n",
    "        for event in events:\n",
    "            self.events.append(Event(event[0], event[1], Datagram(-1, event[2])))\n",
    "    \n",
    "    def process(self, action: list[int]):\n",
    "        reward = 0\n",
    "        for event in self.events:\n",
    "            if event.delay == 0:\n",
    "                reward += self.network.routers[event.destination].receive(event.datagram)\n",
    "        self.events = [event for event in self.events if event.delay != 0]\n",
    "        for event in self.events:\n",
    "            event.delay -= 1\n",
    "        for router in self.network.routers.values():            \n",
    "            event = router.process(action[router.address - 1])\n",
    "            if event is not None:\n",
    "                self.events.append(event)\n",
    "        self.network.generate_random_data()\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 3\n",
      "8 3 1\n",
      "0 2 3\n",
      "----------------\n",
      "10 [2, 3, 2, 2, 3]\n",
      "3 [3]\n",
      "6 [2, 1, 1, 2]\n",
      "----------------\n",
      "reward = 0\n",
      "4 1 3\n",
      "7 3 1\n",
      "8 2 2\n",
      "8 1 3\n",
      "40 1 2\n",
      "10 [3, 2, 2, 3]\n",
      "3 [3]\n",
      "6 [1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "scheduler = Scheduler(network)\n",
    "scheduler.start([[5, 1, 3], [8, 3, 1], [0, 2, 3]])\n",
    "for event in scheduler.events:\n",
    "    print(event.delay, event.destination, event.datagram.destination)\n",
    "print(\"----------------\")\n",
    "for router in network.routers.values():\n",
    "    print(router.size, [datagram.destination for datagram in router.queue.queue])\n",
    "print(\"----------------\")\n",
    "reward = scheduler.process([2, 1, 1])\n",
    "print(f'reward = {reward}')\n",
    "for event in scheduler.events:\n",
    "    print(event.delay, event.destination, event.datagram.destination)\n",
    "for router in network.routers.values():\n",
    "    print(router.size, [datagram.destination for datagram in router.queue.queue])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 1 3\n",
    "8 3 1\n",
    "0 2 3\n",
    "----------------\n",
    "10 [2, 3, 2, 2, 3]\n",
    "3 [3]\n",
    "6 [2, 1, 1, 2]\n",
    "----------------\n",
    "reward = 0\n",
    "4 1 3\n",
    "7 3 1\n",
    "8 2 2\n",
    "8 1 3\n",
    "40 1 2\n",
    "10 [3, 2, 2, 3]\n",
    "3 [3]\n",
    "6 [1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward = 0\n",
      "3 1 3\n",
      "6 3 1\n",
      "7 2 2\n",
      "7 1 3\n",
      "39 1 2\n",
      "40 3 3\n",
      "8 1 3\n",
      "40 1 1\n",
      "10 [2, 2, 3]\n",
      "3 []\n",
      "6 [1, 2]\n"
     ]
    }
   ],
   "source": [
    "reward = scheduler.process([3, 1, 1])\n",
    "print(f'reward = {reward}')\n",
    "for event in scheduler.events:\n",
    "    print(event.delay, event.destination, event.datagram.destination)\n",
    "for router in network.routers.values():\n",
    "    print(router.size, [datagram.destination for datagram in router.queue.queue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reward = 0\n",
    "3 1 3\n",
    "6 3 1\n",
    "7 2 2\n",
    "7 1 3\n",
    "39 1 2\n",
    "40 3 3\n",
    "8 1 3\n",
    "40 1 1\n",
    "10 [2, 2, 3]\n",
    "3 []\n",
    "6 [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, network: Network, scheduler: Scheduler):\n",
    "        self.network = network\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def get_all_states(self):\n",
    "        def get_router_states(router):\n",
    "            router_states = list(product(list(router.adjacents.keys()) + [0], repeat=router.size))\n",
    "            def is_valid(x):\n",
    "                for i in range(len(x)):\n",
    "                    if x[i] == 0 and i < len(x) - 1:\n",
    "                        return all([x[j] == 0 for j in range(i + 1, len(x))])\n",
    "                return True\n",
    "            router_states = filter(is_valid, router_states)\n",
    "            router_states = [list(state) if 0 not in state else [] if state[0] == 0 else list(state[0:state.index(0)]) for state in router_states]\n",
    "            return router_states\n",
    "        aux = product(*[get_router_states(router) for router in self.network.routers.values()])\n",
    "        routers_states = [list(routers_state) for routers_state in aux]\n",
    "\n",
    "        min_delay = min([min([router.adjacents[address][1] for address in router.adjacents]) for router in self.network.routers.values()])\n",
    "        events_states = product(range(min_delay + 1), self.network.routers.keys(), self.network.routers.keys())\n",
    "        events_states = [list(event_state) for event_state in events_states]\n",
    "\n",
    "        return product(events_states, routers_states)\n",
    "    \n",
    "    def get_state(self):\n",
    "        events_state = []\n",
    "        for event in self.scheduler.events:\n",
    "            event_state = [event.delay, event.destination, event.datagram.destination]\n",
    "            events_state.append(event_state)\n",
    "\n",
    "        routers_state = []\n",
    "        for router in self.network.routers.values():\n",
    "            destinations = []\n",
    "            for datagram in router.queue.queue:\n",
    "                destinations.append(datagram.destination)\n",
    "            routers_state.append(destinations)\n",
    "            \n",
    "        return (events_state, routers_state)\n",
    "    \n",
    "    def take_action(self, action):\n",
    "        reward = 0\n",
    "        for router in self.network.routers.values():\n",
    "            reward -= router.queue.length\n",
    "        reward -= len(self.scheduler.events)\n",
    "        reward += self.scheduler.process(action)\n",
    "        new_state = self.get_state()\n",
    "        return reward, new_state\n",
    "    \n",
    "    def start(self, state = None): \n",
    "        if state == None:\n",
    "            state = ([], [[] for i in self.network.routers])\n",
    "        self.scheduler.start(state[0])\n",
    "        self.network.start(state[1])\n",
    "        \n",
    "    def possible_actions(self, state = None):\n",
    "        if state == None:\n",
    "            state = self.get_state()\n",
    "        action = {}\n",
    "        for address in self.network.routers:\n",
    "            if state[1][address - 1] == []:\n",
    "                action[address] = [-1]\n",
    "            else:\n",
    "                action[address] = self.network.routers[address].adjacents\n",
    "        return list(product(*action.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estado atualmente eh um par ordenado com:\n",
    "- 1 elemento: lista de estados dos eventos, onde cada estado eh (delay, destino imediato, destino final)\n",
    "- 2 elemento: lista de estados dos roteadores, onde cada estado corresponde a um roteador (via endereço) e eh uma lista dos destinos dos datagramas (na ordem da fila)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cria Rede Genérica\n",
    "![rede 1](./img/rede1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = Network(4, 1.0, 1)\n",
    "\n",
    "for _ in range(4):\n",
    "    network.add_router(4)\n",
    "\n",
    "network.link(1, 2, 3)\n",
    "network.link(1, 3, 10)\n",
    "network.link(1, 4, 2)\n",
    "network.link(2, 4, 6)\n",
    "\n",
    "scheduler = Scheduler(network)\n",
    "\n",
    "env = Environment(network, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27907440\n"
     ]
    }
   ],
   "source": [
    "print(len(list(env.get_all_states())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [[], [], [], []])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([], [[], [], [], []])\n",
      "[(-1, -1, -1, -1)]\n"
     ]
    }
   ],
   "source": [
    "env.start()\n",
    "print(env.get_state())\n",
    "print(env.possible_actions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[4, 1, 2], [1, 2, 4]], [[2, 4, 3], [4], [1, 2, 1, 1], []])\n",
      "[(2, 1, 1, -1), (2, 4, 1, -1), (3, 1, 1, -1), (3, 4, 1, -1), (4, 1, 1, -1), (4, 4, 1, -1)]\n"
     ]
    }
   ],
   "source": [
    "env.start(([[4, 1, 2], [1, 2, 4]], [[2, 4, 3], [4], [1, 2, 1, 1], []]))\n",
    "print(env.get_state())\n",
    "print(env.possible_actions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "([[3, 1, 2], [0, 2, 4], [10, 3, 2], [6, 4, 4], [10, 1, 1]], [[4, 3], [], [2, 1, 1, 1], []])\n",
      "[(2, -1, 1, -1), (3, -1, 1, -1), (4, -1, 1, -1)]\n"
     ]
    }
   ],
   "source": [
    "env.take_action([3, 4, 1, -1])\n",
    "print(env.get_state())\n",
    "print(env.possible_actions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3, 1)\n",
    "([[3, 1, 2], [0, 2, 4], [10, 3, 2], [6, 4, 4], [10, 1, 1]], [[4, 3], [], [2, 1, 1, 1], []])\n",
    "[(2, -1, 1, -1), (3, -1, 1, -1), (4, -1, 1, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Q_Learning:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.policy = {}\n",
    "        self.values = {}\n",
    "\n",
    "    def q_learning(self, alpha, epsilon, time_steps, gama):\n",
    "        self.initialize() #Initialize value table \n",
    "\n",
    "        self.env.start()\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            state = self.env.get_state()\n",
    "            \n",
    "            if random.random() >= epsilon:\n",
    "                action = max(self.values[state], key = self.values[state].get)\n",
    "            else:\n",
    "                action = random.choice(list(self.values[state].keys())) #ou usar o possible actions\n",
    "\n",
    "            reward, next_state = self.env.take_action(action)\n",
    "            self.values[state][action] += alpha*(reward + gama*max(self.values[next_state].values()) - self.values[state][action])\n",
    "        \n",
    "    def initialize(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StateActionArray:\n",
    "    def __init__(self, env: Environment):\n",
    "        ...\n",
    "    def get(self, state, action):\n",
    "        ...\n",
    "    def set(self, state, action, value):\n",
    "        ...\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, env:Environment, eps: float=0):\n",
    "        ...\n",
    "    def get(self, state):\n",
    "        ...\n",
    "    def set(self, state, action):\n",
    "        ...\n",
    "        \n",
    "def sarsa(env: Environment, returns: StateActionArray, policy: Policy, gamma: float, alpha: float):\n",
    "    \n",
    "    env.reset()\n",
    "    state = env.get_state()\n",
    "    action = policy.get(state)\n",
    "    while True:\n",
    "        reward, next_state = env.take_action(action)\n",
    "        next_action = policy.get(next_state)\n",
    "        current_return = returns.get(state, action)\n",
    "        \n",
    "        next_return = 0\n",
    "        if not env.terminal():\n",
    "            next_return = returns.get(next_state, next_action)\n",
    "\n",
    "        new_return = current_return + alpha * (gamma * next_return - current_return + reward)\n",
    "        returns.set(state, action, new_return)\n",
    "\n",
    "        actions = env.possible_actions()\n",
    "        values = [returns.get(state, act) for act in actions]\n",
    "        policy.set(state, actions[np.argmax(values)])\n",
    "\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "        if env.terminal():\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Episode:\n",
    "    def __init__(self, env : Environment, agent, initial_state, initial_action):\n",
    "        self.env = env\n",
    "        self.initial_state = initial_state\n",
    "        self.initial_action = initial_action\n",
    "        self.pairs = []\n",
    "        self.rewards = []\n",
    "        self.agent = agent\n",
    "        self.steps = 0\n",
    "\n",
    "    def genEpisode(self):\n",
    "        self.env.start(self.initial_state)\n",
    "        state = self.initial_state\n",
    "        action = self.initial_action\n",
    "        while True:\n",
    "            self.pairs.append((state, action))\n",
    "            reward, state = self.env.take_action(action)\n",
    "            self.rewards.append(reward)\n",
    "            self.steps += 1\n",
    "            if (state == -1 or self.steps == 400):\n",
    "                self.steps = len(self.rewards)\n",
    "                return\n",
    "            action = self.agent.choose_action(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_MC:\n",
    "    def __init__(self, env: Environment, strategy, eps=None):\n",
    "        self.env = env\n",
    "        self.hashmap = {}\n",
    "        if strategy == 'ExpStarts':\n",
    "            for state in env.get_all_states():\n",
    "                self.hashmap[state] = env.possible_actions(state)\n",
    "        self.Q_values = {(state, action) : [0, 0] for state in self.hashmap for action in self.hashmap[state]}\n",
    "        self.policy = {state : np.choice(self.hashmap[state])}\n",
    "        self.strategy = strategy\n",
    "        self.eps=eps\n",
    "\n",
    "    def initialize(self):\n",
    "        for state in self.hashmap.keys():\n",
    "            for action in self.hashmap[state]:\n",
    "                self.Q_values[(state, action)] = [0, 0]\n",
    "        for state in self.hashmap.keys():\n",
    "            self.policy[state] = np.choice(self.hashmap[state])\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        if state not in self.hashmap.keys():\n",
    "            self.hashmap[state] = self.env.possible_actions(state)\n",
    "            for action in self.hashmap[state]:\n",
    "                self.Q_values[(state, action)] = [0, 0]\n",
    "        if self.strategy == 'ExpStarts':\n",
    "            return self.policy[state]\n",
    "        else:\n",
    "            if np.random.random() < self.eps:\n",
    "                return np.choice(self.env.possible_actions(state))\n",
    "            else:\n",
    "                return self.policy[state]\n",
    "    \n",
    "    def learn(self, numEpisodes, gamma):\n",
    "        if self.strategy == 'ExpStarts':\n",
    "            self.MC_ExpStarts(numEpisodes, gamma)\n",
    "        else:\n",
    "            self.MC_EpsSoft(numEpisodes, gamma)\n",
    "    \n",
    "    def MC_ExpStarts(self, numEpisodes, gamma):\n",
    "        for _ in range(numEpisodes):\n",
    "            initial_state = random.choice(self.hashmap)\n",
    "            initial_action = random.choice(self.hashmap[initial_state])\n",
    "            episode = Episode(self.env, self, initial_state, initial_action)\n",
    "            episode.genEpisode()\n",
    "            g = 0\n",
    "            for step in range(episode.steps - 1, -1, -1):\n",
    "                g = gamma * g + episode.rewards[step]\n",
    "                pair = episode.pairs[step]\n",
    "                if (pair not in episode.pairs[0:step]):\n",
    "                    self.Q_values[pair][0] = (self.Q_values[pair][0] * self.Q_values[pair][1] + g) / (self.Q_values[pair][1] + 1)\n",
    "                    self.Q_values[pair][1] += 1\n",
    "                    self.policy[pair[0]] = self.actions[pair[0]][np.argmax([self.Q_values[(pair[0], action)][0] for action in self.actions[pair[0]]])]\n",
    "    \n",
    "    def MC_EpsSoft(self, numEpisodes, gamma): # implementação com eps greedy\n",
    "        for _ in range(numEpisodes):\n",
    "            initial_state = self.env.get_state()\n",
    "            initial_action = self.choose_action(initial_state)\n",
    "            episode = Episode(self.env, self, initial_state, initial_action)\n",
    "            episode.genEpisode()\n",
    "            g = 0\n",
    "            for step in range(episode.steps - 1, -1, -1):\n",
    "                g = gamma * g + episode.rewards[step]\n",
    "                pair = episode.pairs[step]\n",
    "                if (pair not in episode.pairs[0:step]):\n",
    "                    self.Q_values[pair][0] = (self.Q_values[pair][0] * self.Q_values[pair][1] + g) / (self.Q_values[pair][1] + 1)\n",
    "                    self.Q_values[pair][1] += 1\n",
    "                    self.policy[pair[0]] = self.actions[pair[0]][np.argmax([self.Q_values[(pair[0], action)][0] for action in self.actions[pair[0]]])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
