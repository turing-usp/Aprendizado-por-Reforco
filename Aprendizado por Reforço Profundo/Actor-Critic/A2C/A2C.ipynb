{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjGWyD9Hyfg-"
   },
   "source": [
    "# A2C - Advantage Actor Critic\n",
    "\n",
    "Como vimos na aula de Policy Gradients, existem algoritmos capazes de aprender a política diretamente, utilizando gradiente ascendente neste processo. Porém, modelos como REINFORCE sofrem com grande variância. Para tentar solucionar este problema, surge a ideia de utilizar uma estimativa do retorno. Cada uma dessas estimativas leva a diferentes algoritmos Actor-Critic. Hoje, vamos abordar uma delas, a Advantage (vantagem):\n",
    "\n",
    "\\begin{align*}\n",
    "  \\nabla_\\theta J(\\theta) &=  \\mathbb{E}_{\\pi_\\theta} [\\nabla_\\theta log \\pi_\\theta(s,a)\\ G_t]\\ \\ \\ \\text{REINFORCE} \\\\\n",
    "\n",
    "  \\nabla_\\theta J(\\theta) &=  \\mathbb{E}_{\\pi_\\theta} [\\nabla_\\theta log \\pi_\\theta(s,a)\\ Q^w(s,a)]\\ \\ \\ \\text{Q Actor-Critic} \\\\\n",
    "\n",
    "  \\nabla_\\theta J(\\theta) &=  \\mathbb{E}_{\\pi_\\theta} [\\nabla_\\theta log \\pi_\\theta(s,a)\\ A^w(s,a)]\\ \\ \\ \\text{Advantage Actor-Critic} \\\\\n",
    "\n",
    "  \\nabla_\\theta J(\\theta) &=  \\mathbb{E}_{\\pi_\\theta} [\\nabla_\\theta log \\pi_\\theta(s,a)\\ \\delta]\\ \\ \\ \\text{TD Actor-Critic}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "## O Ator e o Crítico\n",
    "\n",
    "Antes de entrarmos no A2C em si, é interessante explorar o que cada parte do algoritmo faz. Resumindo, o **crítico** atualiza as estimativas da função valor enquanto o **ator** busca atualizar a política na direção sugerida pelo crítico.\n",
    "\n",
    "![interacao actor-critic](https://miro.medium.com/max/390/1*-GfRVLWhcuSYhG25rN0IbA.png)\n",
    "\n",
    "Para entender um pouco melhor, de uma forma mais alto nível, [recomendo essa história em quadrinhos](https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752) (sim, existem historias em quadrinhos de RL)\n",
    "\n",
    "Enxergando de outra forma, temos que o crítico é a função valor, medindo o quão boas são as ações tomadas, enquanto o ator é a função política, controlando as ações.\n",
    "\n",
    "* Ator: $\\pi(s, a, \\theta)$\n",
    "* Crítico: $\\hat{q}(s, a, \\omega)$\n",
    "\n",
    "\n",
    "## Advantage\n",
    "\n",
    "Uma das baselines que pode ser desenvolvida é a chamada vantagem, que é definida da seguinte forma:\n",
    "\n",
    "$$A(s, a) = Q(s, a) - V(s)$$\n",
    "\n",
    "Em resumo, a vantagem busca medir de forma *relativa* o valor de uma ação comparando com o valor médio das ações naquele estado. Se o valor da vantagem é positivo, levamos o nosso gradiente nesta direção.\n",
    "\n",
    "Uma das formas de estimar o valor de A(s, a) é usando o nosso velho amigo **bootstrapping**, onde podemos estimar o Q da seguinte forma:\n",
    "\n",
    "$$Q(s,a) = r + \\gamma V(s')$$\n",
    "\n",
    "Reescrevendo a vantagem, temos que ela pode ser aproximada a seguir:\n",
    "\n",
    "$$A(s,a) = r + \\gamma V(s') - V(s)$$\n",
    "\n",
    "É interessante notar que essa forma de aproximar a vantagem usa o mesmo cálculo do Erro de Temporal Difference: $\\delta_t = r + \\gamma V(s') - V(s)$. Apesar disso, a vantagem também pode ser aproximada de outras maneiras.\n",
    "\n",
    "Com essa fórmula, precisamos estimar somente V e não Q. Existem outras formas de estimar a vantagem, como a [Generalized Advantage Estimation](https://arxiv.org/pdf/1506.02438.pdf)\n",
    "\n",
    "Dessa forma, podemos estimar o gradiente do Advantage Actor-Critic pela seguinte equação:\n",
    "\n",
    "$$\\nabla_\\theta J(\\theta) \\approx \\sum_{t = 0}^{T-1}  \\nabla_\\theta log \\pi_\\theta(s,a)(r_{t+1} + \\gamma V(s_{t+1}) - V(s_t))$$\n",
    "\n",
    "### A3C vs A2C\n",
    "\n",
    "O algoritmo inicial foi o A3C (Asynchronous Advantage Actor Critic), por meio de um paper da Deepmind ([Paper de A3C](https://arxiv.org/abs/1602.01783)). Segundo a OpenAI, a parte assíncrona do A3C não traz grande vantagem e é menos eficiente, por isso a ideia do A2C. Não tenho capacidade de entrar no mérito, então vou só pontuar as diferenças.\n",
    "\n",
    "\n",
    "Ambos os algoritmos atuam em múltiplos ambientes simultâneos, mas enquanto o A3C é atualizado cada vez que um deles termina uma batch de experiências, por isso assíncrono, o A2C espera todos os agentes obterem uma batch para então atualizar com todas simultaneamente, usando a média do update. As diferenças podem ser conferidas [neste link da OpenAI](https://openai.com/blog/baselines-acktr-a2c/).\n",
    "\n",
    "## Algoritmo do A2C\n",
    "\n",
    "O pseudocódigo do A2C pode ser visto na imagem a seguir:\n",
    "\n",
    "<img src=\"imgs/A2C.svg\" width=\"800\" title=\"pseudocode\" />\n",
    "\n",
    "\n",
    "É importante ressaltar que essa versão utiliza duas redes neurais, uma para o crítico e outra para o ator, mas implementações com uma só rede são possíveis e serão mostradas abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f\n",
    "\n",
    "https://towardsdatascience.com/introduction-to-actor-critic-7642bdb2b3d2\n",
    "\n",
    "https://www.freecodecamp.org/news/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d/\n",
    "\n",
    "[http://incompleteideas.net/book/first/ebook](http://incompleteideas.net/book/first/ebook/node66.html#:~:text=Actor%2Dcritic%20methods%20are%20TD,independent%20of%20the%20value%20function.&text=This%20scalar%20signal%20is%20the,%3A%20The%20actor%2Dcritic%20architecture)\n",
    "\n",
    "https://openai.com/blog/baselines-acktr-a2c/\n",
    "\n",
    "https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html#id14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btLijj8y7gLH"
   },
   "source": [
    "# Código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkTEyq25ms2B"
   },
   "source": [
    "## Ator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JOdt9KwNmcFR"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    \"\"\"Rede do Ator.\"\"\"\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        \"\"\"Inicializa a rede.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        observation_shape: int\n",
    "        Formato do estado do ambiente.\n",
    "        \n",
    "        action_shape: int\n",
    "        Número de ações do ambiente.\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(observation_shape, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.linear3 = nn.Linear(128, action_shape)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Calcula a probabilidade de ação para o estado atual.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        state: np.array\n",
    "        Estado atual.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        probs: Categorical\n",
    "        Distribuição de probabilidade das ações.\n",
    "        \"\"\"\n",
    "        dists = F.relu(self.linear1(state))\n",
    "        dists = F.relu(self.linear2(dists))\n",
    "        dists = F.softmax(self.linear3(dists), dim=1)\n",
    "        probs = Categorical(dists)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDbUOyZDmu6o"
   },
   "source": [
    "## Crítico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L2Ne0at-msW4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    \"\"\"Rede do Crítico.\"\"\"\n",
    "    def __init__(self, observation_shape):\n",
    "        \"\"\"Inicializa a rede.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        observation_shape: int\n",
    "        Formato do estado do ambiente.\n",
    "        \"\"\"\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(observation_shape, 64)\n",
    "        self.linear2 = nn.Linear(64, 64)\n",
    "        self.linear3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Calcula o valor do estado atual.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        state: np.array\n",
    "        Estado atual.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        v: float\n",
    "        Valor do estado atual.\n",
    "        \"\"\"\n",
    "        v = F.relu(self.linear1(state))\n",
    "        v = F.relu(self.linear2(v))\n",
    "        v = self.linear3(v)\n",
    "\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZiSoaCSnX-3"
   },
   "source": [
    "## Memory Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oh5ztI22nXiX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MemoryBuffer:\n",
    "    \"\"\"Memory Buffer Buffer para A2C.\"\"\"\n",
    "    def __init__(self, max_length, observation_space):\n",
    "        \"\"\"Cria um Replay Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        max_length: int\n",
    "            Tamanho máximo do Replay Buffer.\n",
    "        observation_space: int\n",
    "            Tamanho do espaço de observação.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.actions = np.zeros((max_length), dtype=np.int32)\n",
    "        self.rewards = np.zeros((max_length), dtype=np.float32)\n",
    "        self.next_states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.dones = np.zeros((max_length), dtype=np.float32)\n",
    "\n",
    "    def update(self, states, actions, rewards, next_states, dones):\n",
    "        \"\"\"Adiciona uma experiência ao Replay Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        state: np.array\n",
    "            Estado da transição.\n",
    "        action: int\n",
    "            Ação tomada.\n",
    "        reward: float\n",
    "            Recompensa recebida.\n",
    "        state: np.array\n",
    "            Estado seguinte.\n",
    "        done: int\n",
    "            Flag indicando se o episódio acabou.\n",
    "        \"\"\"\n",
    "        self.states[self.length] = states\n",
    "        self.actions[self.length] = actions\n",
    "        self.rewards[self.length] = rewards\n",
    "        self.next_states[self.length] = next_states\n",
    "        self.dones[self.length] = dones\n",
    "        self.length += 1\n",
    "\n",
    "    def get_batch(self):\n",
    "        \"\"\"Retorna um batch de experiências.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            Tamanho do batch de experiências.\n",
    "\n",
    "        Retorna\n",
    "        -------\n",
    "        states: np.array\n",
    "            Batch de estados.\n",
    "        actions: np.array\n",
    "            Batch de ações.\n",
    "        rewards: np.array\n",
    "            Batch de recompensas.\n",
    "        next_states: np.array\n",
    "            Batch de estados seguintes.\n",
    "        dones: np.array\n",
    "            Batch de flags indicando se o episódio acabou.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "\n",
    "        return (self.states, self.actions, self.rewards, self.next_states, self.dones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u-dalX7m-Co"
   },
   "source": [
    "## Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xPhl6Qgnm9dX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class A2C:\n",
    "    def __init__(self, observation_space, action_space, p_lr=5e-4, v_lr=7e-4, gamma=0.99, entropy_coef=0.005, n_steps=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.entropy_coef = entropy_coef\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "        self.memory = MemoryBuffer(n_steps, observation_space.shape[0])\n",
    "\n",
    "        self.actor = Actor(observation_space.shape[0], action_space.n).to(self.device)\n",
    "        self.critic = Critic(observation_space.shape[0]).to(self.device)\n",
    "\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=p_lr)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=v_lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        probs = self.actor.forward(state)\n",
    "        \n",
    "        action = probs.sample().cpu().detach().item()\n",
    "        return action\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.update(state, action, reward, next_state, done)\n",
    "\n",
    "    def compute_advantages(self, rewards, dones, v, v2):\n",
    "        T = len(rewards)\n",
    "\n",
    "        returns = torch.zeros_like(rewards).to(self.device)\n",
    "        advantages = torch.zeros_like(rewards).to(self.device)\n",
    "        \n",
    "        next_return = torch.tensor(v2[-1], dtype=rewards.dtype).to(self.device)\n",
    "\n",
    "        not_dones = 1 - dones\n",
    "        advantages = rewards + not_dones * self.gamma * v2 - v\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            returns[t] = next_return = rewards[t] + self.gamma * not_dones[t] * next_return\n",
    "\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8) # Normalização\n",
    "\n",
    "        return advantages, returns\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.length < self.n_steps:\n",
    "            return\n",
    "\n",
    "        (states, actions, rewards, next_states, dones) = self.memory.get_batch()\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.FloatTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(-1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(-1).to(self.device)\n",
    "\n",
    "        v = self.critic.forward(states)\n",
    "        with torch.no_grad():\n",
    "          v2 = self.critic.forward(next_states)\n",
    "\n",
    "        advantages, returns = self.compute_advantages(rewards, dones, v, v2)\n",
    "\n",
    "        probs = self.actor.forward(states)\n",
    "        logp = -probs.log_prob(actions)\n",
    "        entropy = probs.entropy().mean()\n",
    "\n",
    "        policy_loss =   (logp.unsqueeze(-1) * advantages.detach()).mean()\n",
    "        value_loss =    F.mse_loss(v, returns.detach())\n",
    "        entropy_loss = -self.entropy_coef * entropy\n",
    "\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        (policy_loss + entropy_loss).backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        return float(policy_loss + entropy_loss + value_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu7U6Vmzoydm"
   },
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zI1aZ7DypOfN"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import deque\n",
    "\n",
    "def train(agent, env, total_timesteps):\n",
    "    total_reward = 0\n",
    "    episode_returns = deque(maxlen=20)\n",
    "    avg_returns = []\n",
    "\n",
    "    state = env.reset()\n",
    "    timestep = 0\n",
    "    episode = 0\n",
    "\n",
    "    while timestep < total_timesteps:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        loss = agent.train()\n",
    "        timestep += 1\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            episode_returns.append(total_reward)\n",
    "            episode += 1\n",
    "            next_state = env.reset()\n",
    "\n",
    "        if episode_returns:\n",
    "            avg_returns.append(np.mean(episode_returns))\n",
    "\n",
    "        total_reward *= 1 - done\n",
    "        state = next_state\n",
    "\n",
    "        ratio = math.ceil(100 * timestep / total_timesteps)\n",
    "\n",
    "        avg_return = avg_returns[-1] if avg_returns else np.nan\n",
    "        \n",
    "        print(f\"\\r[{ratio:3d}%] timestep = {timestep}/{total_timesteps}, episode = {episode:3d}, avg_return = {avg_return:10.4f}\", end=\"\")\n",
    "\n",
    "    return avg_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1OGWuPmeox9X"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BMax8WJxo01m"
   },
   "outputs": [],
   "source": [
    "agent = A2C(env.observation_space, env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "IcWebqIBo2PG",
    "outputId": "03febf33-a844-449b-80f0-225a840f400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[  1%] timestep = 1/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 2/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 3/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 4/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 5/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 6/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 7/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 8/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 9/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 10/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 11/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 12/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 13/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 14/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 15/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 16/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 17/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 18/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 19/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 20/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 21/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 22/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 23/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 24/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 25/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 26/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 27/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 28/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 29/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 30/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 31/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 32/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 33/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 34/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 35/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 36/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 37/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 38/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 39/75000, episode =   1, avg_return =    21.0000\r",
      "[  1%] timestep = 40/75000, episode =   2, avg_return =    20.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] timestep = 75000/75000, episode = 960, avg_return =   340.3500"
     ]
    }
   ],
   "source": [
    "returns = train(agent, env, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(returns, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como foi possível observar, não obtivemos uma performance muito boa com o nosso algoritmo. Dessa forma, para melhorar o nosso resultado, podemos juntar as duas redes de Ator e de Crítico em uma só, usando somente uma função de custo, acelerando o treinamento e o tornando mais robusto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYBC2Z14va6v"
   },
   "source": [
    "##  Rede Dividida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "41fE0sOivQ8S"
   },
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.policy1 = nn.Linear(observation_shape, 64)\n",
    "        self.policy2 = nn.Linear(64, 64)\n",
    "        self.policy3 = nn.Linear(64, action_shape)\n",
    "        \n",
    "        self.value1 = nn.Linear(observation_shape, 64)\n",
    "        self.value2 = nn.Linear(64, 64)\n",
    "        self.value3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dists = torch.tanh(self.policy1(state))\n",
    "        dists = torch.tanh(self.policy2(dists))\n",
    "        dists = F.softmax(self.policy3(dists), dim=-1)\n",
    "        probs = Categorical(dists)\n",
    "        \n",
    "        v = torch.tanh(self.value1(state))\n",
    "        v = torch.tanh(self.value2(v))\n",
    "        v = self.value3(v)\n",
    "\n",
    "        return probs, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "E55ppd0ovfH4"
   },
   "outputs": [],
   "source": [
    "class SharedA2C:\n",
    "    def __init__(self, observation_space, action_space, lr=7e-4, gamma=0.99, lam=0.95, vf_coef=0.5, entropy_coef=0.005, n_steps=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.vf_coef = vf_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "        self.memory = MemoryBuffer(n_steps, observation_space.shape[0])\n",
    "\n",
    "        self.actorcritic = ActorCritic(observation_space.shape[0], action_space.n).to(self.device)\n",
    "        self.actorcritic_optimizer = optim.Adam(self.actorcritic.parameters(), lr=lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        probs, _ = self.actorcritic.forward(state)\n",
    "        action = probs.sample().cpu().detach().item()\n",
    "        return action\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.update(state, action, reward, next_state, done)\n",
    "\n",
    "    def compute_gae(self, rewards, dones, v, v2):\n",
    "        T = len(rewards)\n",
    "\n",
    "        returns = torch.zeros_like(rewards).to(self.device)\n",
    "        gaes = torch.zeros_like(rewards).to(self.device)\n",
    "        \n",
    "        future_gae = torch.tensor(0.0, dtype=rewards.dtype).to(self.device)\n",
    "        next_return = torch.tensor(v2[-1], dtype=rewards.dtype).to(self.device)\n",
    "\n",
    "        not_dones = 1 - dones\n",
    "        deltas = rewards + not_dones * self.gamma * v2 - v\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            returns[t] = next_return = rewards[t] + self.gamma * not_dones[t] * next_return\n",
    "            gaes[t] = future_gae = deltas[t] + self.gamma * self.lam * not_dones[t] * future_gae\n",
    "\n",
    "        gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8) # Normalização\n",
    "\n",
    "        return gaes, returns\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.length < self.n_steps:\n",
    "            return\n",
    "\n",
    "        (states, actions, rewards, next_states, dones) = self.memory.get_batch()\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.FloatTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(-1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(-1).to(self.device)\n",
    "\n",
    "        probs, v = self.actorcritic.forward(states)\n",
    "        with torch.no_grad():\n",
    "          _, v2 = self.actorcritic.forward(next_states)\n",
    "\n",
    "        advantages, returns = self.compute_gae(rewards, dones, v, v2)\n",
    "\n",
    "        logp = -probs.log_prob(actions)\n",
    "        entropy = probs.entropy().mean()\n",
    "\n",
    "        policy_loss =   (logp.unsqueeze(-1) * advantages.detach()).mean()\n",
    "        value_loss =    self.vf_coef * F.mse_loss(v, returns.detach())\n",
    "        entropy_loss = -self.entropy_coef * entropy\n",
    "\n",
    "        self.actorcritic_optimizer.zero_grad()\n",
    "        (policy_loss + entropy_loss + value_loss).backward()\n",
    "        self.actorcritic_optimizer.step()\n",
    "\n",
    "        return policy_loss + entropy_loss + value_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SGtTSQ-pwDrI"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hyUcshjiwDrL"
   },
   "outputs": [],
   "source": [
    "agent = SharedA2C(env.observation_space, env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "CMrVG7wHwDrN",
    "outputId": "2046e3bc-d957-487b-e431-5215bca2679c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[  1%] timestep = 1/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 2/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 3/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 4/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 5/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 6/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 7/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 8/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 9/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 10/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 11/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 12/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 13/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 14/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 15/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 16/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 17/75000, episode =   0, avg_return =        nan\r",
      "[  1%] timestep = 18/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 19/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 20/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 21/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 22/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 23/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 24/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 25/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 26/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 27/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 28/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 29/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 30/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 31/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 32/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 33/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 34/75000, episode =   1, avg_return =    18.0000\r",
      "[  1%] timestep = 35/75000, episode =   1, avg_return =    18.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] timestep = 75000/75000, episode = 661, avg_return =   500.0000"
     ]
    }
   ],
   "source": [
    "returns = train(agent, env, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(returns, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxAjgrZ81D0e"
   },
   "source": [
    "## Múltiplos Ambientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9fmNerrB1cAU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultipleMemoryBuffer:\n",
    "    def __init__(self, max_length, env_num, observation_space):\n",
    "        self.length = 0\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.states = np.zeros((max_length, env_num, observation_space), dtype=np.float32)\n",
    "        self.actions = np.zeros((max_length, env_num), dtype=np.int32)\n",
    "        self.rewards = np.zeros((max_length, env_num), dtype=np.float32)\n",
    "        self.next_states = np.zeros((max_length, env_num, observation_space), dtype=np.float32)\n",
    "        self.dones = np.zeros((max_length, env_num), dtype=np.float32)\n",
    "\n",
    "    def update(self, states, actions, rewards, next_states, dones):\n",
    "        self.states[self.length] = states\n",
    "        self.actions[self.length] = actions\n",
    "        self.rewards[self.length] = rewards\n",
    "        self.next_states[self.length] = next_states\n",
    "        self.dones[self.length] = dones\n",
    "        self.length += 1\n",
    "\n",
    "    def get_batch(self):\n",
    "        self.length = 0\n",
    "\n",
    "        return (self.states, self.actions, self.rewards, self.next_states, self.dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "99fj4r0U1Caq"
   },
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.policy1 = nn.Linear(observation_shape, 64)\n",
    "        self.policy2 = nn.Linear(64, 64)\n",
    "        self.policy3 = nn.Linear(64, action_shape)\n",
    "        \n",
    "        self.value1 = nn.Linear(observation_shape, 64)\n",
    "        self.value2 = nn.Linear(64, 64)\n",
    "        self.value3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dists = torch.tanh(self.policy1(state))\n",
    "        dists = torch.tanh(self.policy2(dists))\n",
    "        dists = F.softmax(self.policy3(dists), dim=-1)\n",
    "        probs = Categorical(dists)\n",
    "        \n",
    "        v = torch.tanh(self.value1(state))\n",
    "        v = torch.tanh(self.value2(v))\n",
    "        v = self.value3(v)\n",
    "\n",
    "        return probs, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZgpS39h31JDg"
   },
   "outputs": [],
   "source": [
    "class SharedA2C:\n",
    "    def __init__(self, observation_space, action_space, env_num, lr=7e-4, gamma=0.99, lam=0.95, vf_coef=0.5, entropy_coef=0.005, n_steps=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.vf_coef = vf_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "        self.memory = MultipleMemoryBuffer(n_steps, env_num, observation_space.shape[0])\n",
    "\n",
    "        self.actorcritic = ActorCritic(observation_space.shape[0], action_space.n).to(self.device)\n",
    "        self.actorcritic_optimizer = optim.Adam(self.actorcritic.parameters(), lr=lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device)\n",
    "        probs, _ = self.actorcritic.forward(state)\n",
    "        action = probs.sample().cpu().detach().numpy()\n",
    "        return action\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.update(state, action, reward, next_state, done)\n",
    "\n",
    "    def compute_gae(self, rewards, dones, v, v2):\n",
    "        T = len(rewards)\n",
    "\n",
    "        returns = torch.zeros_like(rewards).to(self.device)\n",
    "        gaes = torch.zeros_like(rewards).to(self.device)\n",
    "        \n",
    "        future_gae = torch.tensor(0.0, dtype=rewards.dtype).to(self.device)\n",
    "        next_return = torch.tensor(v2[-1], dtype=rewards.dtype).to(self.device)\n",
    "\n",
    "        not_dones = 1 - dones\n",
    "        deltas = rewards + not_dones * self.gamma * v2 - v\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            returns[t] = next_return = rewards[t] + self.gamma * not_dones[t] * next_return\n",
    "            gaes[t] = future_gae = deltas[t] + self.gamma * self.lam * not_dones[t] * future_gae\n",
    "\n",
    "        gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8) # Normalização\n",
    "\n",
    "        return gaes, returns\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.length < self.n_steps:\n",
    "            return\n",
    "\n",
    "        (states, actions, rewards, next_states, dones) = self.memory.get_batch()\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.FloatTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(-1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(-1).to(self.device)\n",
    "\n",
    "        probs, v = self.actorcritic.forward(states)\n",
    "        with torch.no_grad():\n",
    "          _, v2 = self.actorcritic.forward(next_states)\n",
    "\n",
    "        advantages, returns = self.compute_gae(rewards, dones, v, v2)\n",
    "\n",
    "        logp = -probs.log_prob(actions)\n",
    "        entropy = probs.entropy().mean()\n",
    "\n",
    "        policy_loss =   (logp.unsqueeze(-1) * advantages.detach()).mean()\n",
    "        value_loss =    self.vf_coef * F.mse_loss(v, returns.detach())\n",
    "        entropy_loss = -self.entropy_coef * entropy\n",
    "\n",
    "        self.actorcritic_optimizer.zero_grad()\n",
    "        (policy_loss + entropy_loss + value_loss).backward()\n",
    "        self.actorcritic_optimizer.step()\n",
    "\n",
    "        return policy_loss + entropy_loss + value_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zhpeeumo1Jvg"
   },
   "outputs": [],
   "source": [
    "env = gym.vector.make(\"CartPole-v1\", num_envs=8, asynchronous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jhILSotY2D4q"
   },
   "outputs": [],
   "source": [
    "agent = SharedA2C(env.single_observation_space, env.single_action_space, env.num_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Y_Ype5FR2R4i"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def vector_train(agent, env, total_timesteps):\n",
    "    total_rewards = [[] for _ in range(env.num_envs)]\n",
    "    avg_total_rewards = []\n",
    "\n",
    "    total_reward = np.zeros(env.num_envs)\n",
    "    observations = env.reset()\n",
    "    timestep = 0\n",
    "    episode = 0\n",
    "\n",
    "    t = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while timestep < total_timesteps:\n",
    "        actions = agent.act(observations)\n",
    "        next_observations, rewards, dones, _ = env.step(actions)\n",
    "        agent.remember(observations, actions, rewards, next_observations, dones)\n",
    "        agent.train()\n",
    "        \n",
    "        timestep += len(observations)\n",
    "        t += 1\n",
    "\n",
    "        total_reward += rewards\n",
    "\n",
    "        for i in range(env.num_envs):\n",
    "            if dones[i]:\n",
    "                total_rewards[i].append((t, timestep, total_reward[i]))\n",
    "                episode += 1\n",
    "\n",
    "        if any(G for G in total_rewards):\n",
    "            episode_returns = sorted(\n",
    "                list(np.concatenate([G for G in total_rewards if G])),\n",
    "                key=lambda x: x[1]\n",
    "            )\n",
    "\n",
    "            avg_total_rewards.append(np.mean([G[-1] for G in episode_returns[-20:]]))\n",
    "\n",
    "        total_reward *= 1 - dones\n",
    "        observations = next_observations\n",
    "\n",
    "        ratio = math.ceil(100 * timestep / total_timesteps)\n",
    "        uptime = math.ceil(time.time() - start_time)\n",
    "\n",
    "        avg_return = avg_total_rewards[-1] if avg_total_rewards else np.nan\n",
    "\n",
    "        print(f\"\\r[{ratio:3d}% / {uptime:3d}s] timestep = {timestep}/{total_timesteps}, episode = {episode:3d}, avg_return = {avg_return:10.4f}\", end=\"\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    return avg_total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "O9tdu0NF2bXd",
    "outputId": "5285a9d3-8c92-4340-9858-408851a77f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[  1% /   1s] timestep = 8/125000, episode =   0, avg_return =        nan\r",
      "[  1% /   1s] timestep = 16/125000, episode =   0, avg_return =        nan\r",
      "[  1% /   1s] timestep = 24/125000, episode =   0, avg_return =        nan\r",
      "[  1% /   1s] timestep = 32/125000, episode =   0, avg_return =        nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100% / 163s] timestep = 125000/125000, episode = 1219, avg_return =   360.8500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "returns = vector_train(agent, env, 125000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(returns, 'r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A2C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}