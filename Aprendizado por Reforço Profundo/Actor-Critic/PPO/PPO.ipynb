{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Policy Optimization (PPO)\n",
    "\n",
    "Como vimos na aula de A2C, uma função objetivo muito utilizada é:\n",
    "\n",
    "$$\n",
    "    J(\\theta) =  \\mathbb{E}_{s,a\\sim\\pi_\\theta} [A^{\\pi_\\theta}_w(s,a)], \\qquad\n",
    "    \\nabla_\\theta J(\\theta) =  \\mathbb{E}_{s,a\\sim\\pi_\\theta} [\\nabla_\\theta \\log \\pi_\\theta(a|s)\\cdot A^{\\pi_\\theta}_w(s,a)].\n",
    "$$\n",
    "\n",
    "Os índices na função _advantage_ $A$ indicam que $A$ depende tanto dos pesos $w$ utilizados para calcular o estimar de cada estado, quanto da política $\\pi_\\theta$, que determina quais trajetórias o agente vai seguir dentro do ambiente.\n",
    "\n",
    "> Obs: pode-se mostrar que essa formulação é equivalente à formulação que utiliza somatórias no tempo:\n",
    "$$\n",
    "    J(\\theta) =  \\mathbb{E}_{(s_0,a_0,\\dots)\\sim\\pi_\\theta} \\left[\\sum_{t=0}^\\infty \\gamma^t A^{\\pi_\\theta}_w(s_t,a_t)\\right], \\qquad\n",
    "    \\nabla_\\theta J(\\theta) =  \\mathbb{E}_{(s_0,a_0,\\dots)\\sim\\pi_\\theta} \\left[\\sum_{t=0}^\\infty \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t)\\cdot A^{\\pi_\\theta}_w(s_t,a_t)\\right].\n",
    "$$\n",
    "\n",
    "Note que uma pequena variação no espaço de parâmetros ($\\Delta\\theta = \\alpha\\nabla_\\theta J$) pode causar uma grande variação no espaço de políticas. Isso significa que, em geral, a taxa de aprendizado $\\alpha$ não pode ser muito alta; caso contrário, corremos o risco de obter uma nova política que não funcione. Consequentemente, a eficiência amostral de A2C também é limitada.\n",
    "\n",
    "\n",
    "## Trust Region Policy Optimization (TRPO)\n",
    "\n",
    "Uma maneira de resolver esse problema é limitar as variações na política. Para isso, vamos utilizar a divergência KL $KL(\\pi_1 || \\pi_2)$, que pode ser, simplificadamente, encarada como uma medida da diferença entre duas políticas (ou, em geral, duas distribuições de probabilidade).\n",
    "\n",
    "TRPO define uma região de confiança (trust region) para garantir que a política nova não se distancie demais da política antiga:\n",
    "$$E_{s\\sim\\pi_{\\theta_{\\mathrm{old}}}}\\bigl[KL\\bigl(\\pi_{\\mathrm{old}}(\\cdot|s)\\,||\\,\\pi(\\cdot|s)\\bigr)\\bigr] \\le \\delta.$$\n",
    "\n",
    "No entanto, maximizar a função objetivo de A2C sujeito a essas restrições é um pouco complicado. Então, vamos utilizar uma aproximação da função objetivo de A2C:\n",
    "\n",
    "$$L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right].$$\n",
    "\n",
    "Ou seja, TRPO consiste em:\n",
    "$$\\text{maximizar } E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right] \\text{ sujeito a } E_{s\\sim\\pi_{\\theta_{\\mathrm{old}}}}\\bigl[KL\\bigl(\\pi_{\\mathrm{old}}(\\cdot|s)\\,||\\,\\pi(\\cdot|s)\\bigr)\\bigr] \\le \\delta.$$\n",
    "\n",
    "> Para entender como chegamos $L(\\theta_{\\mathrm{old}},\\theta)$ é uma aproximação de $J(\\theta)$, podemos fazer:\n",
    "\\begin{align*}\n",
    "J(\\theta) &= E_{\\pi_\\theta}[A^{\\pi_\\theta}(s,a)] \\\\\n",
    "        &= E_{\\pi_\\theta}[A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)] \\\\\n",
    "\t\t&= \\sum_{s,a} \\rho_{\\pi_\\theta}(s)\\cdot \\pi_\\theta(a|s) \\cdot A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&= \\sum_{s,a} \\rho_{\\pi_\\theta}(s)\\cdot \\pi_{\\theta_{\\mathrm{old}}}(a|s) \\cdot \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&\\approx \\sum_{s,a} \\rho_{\\pi_{\\theta_{\\mathrm{old}}}}(s)\\cdot \\pi_{\\theta_{\\mathrm{old}}}(a|s) \\cdot \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a) \\\\\n",
    "\t\t&= E_{\\pi_{\\theta_{\\mathrm{old}}}} \\left[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)} A^{\\pi_\\theta}(s,a)\\right]\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "## Proximal Policy Optimization (PPO)\n",
    "\n",
    "Como já foi mencionado, a restrição ($KL < \\delta$) imposta em TRPO torna o algoritmo relativamente complicado. PPO é uma tentativa de simplificar esse algoritmo. Ao invés de utilizar trust regions, PPO mexe diretamente com a função objetivo:\n",
    "\n",
    "$$\n",
    "    L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\Bigl[\\min\\left(r A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a),\\, \\operatorname{clip}(r,1-\\varepsilon,1+\\varepsilon) A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a)\\right)\\Bigr],\n",
    "    \\quad\n",
    "    r = \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{\\mathrm{old}}}(a|s)}.\n",
    "$$\n",
    "Essa função pode ser reescrita como:\n",
    "$$\n",
    "    L(\\theta_{\\mathrm{old}},\\theta) = E_{s,a\\sim\\pi_{\\theta_{\\mathrm{old}}}} \\Bigl[\\min\\left(r A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a),\\, g(\\varepsilon, A^{\\pi_{\\theta_{\\mathrm{old}}}}(s,a))\\right)\\Bigr],\n",
    "    \\quad\n",
    "    g(\\varepsilon, A) = \\begin{cases}\n",
    "        (1+\\varepsilon) A, & A \\ge 0 \\\\\n",
    "        (1-\\varepsilon) A,  & A < 0.\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Nota-se que:\n",
    "- Quando a vantagem é positiva, se $r$ aumentar, então $L$ aumenta. No entanto, esse benefício é limitado pelo clip: se $r > 1+\\varepsilon$, não há mais benefício para $r$ aumentar.\n",
    "- Quando a vantagem é negativa, se $r$ diminuir, então $L$ aumenta. No entanto, esse benefício é limitado pelo clip: se $r < 1-\\varepsilon$, não há mais benefício para $r$ diminuir.\n",
    "\n",
    "A seguinte imagem pode te ajudar a visualizar o clip. Note que todos os valores fora do clip estipulado estão constantes:\n",
    "\n",
    "![imagem ilustrando o clip](imgs/clip.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Divida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.policy1 = nn.Linear(observation_shape, 64)\n",
    "        self.policy2 = nn.Linear(64, 64)\n",
    "        self.policy3 = nn.Linear(64, action_shape)\n",
    "        \n",
    "        self.value1 = nn.Linear(observation_shape, 64)\n",
    "        self.value2 = nn.Linear(64, 64)\n",
    "        self.value3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dists = torch.relu(self.policy1(state))\n",
    "        dists = torch.relu(self.policy2(dists))\n",
    "        dists = F.softmax(self.policy3(dists), dim=-1)\n",
    "        probs = Categorical(dists)\n",
    "        \n",
    "        v = torch.relu(self.value1(state))\n",
    "        v = torch.relu(self.value2(v))\n",
    "        v = self.value3(v)\n",
    "\n",
    "        return probs, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MemoryBuffer:\n",
    "    \"\"\"Memory Buffer para PPO.\"\"\"\n",
    "    def __init__(self, max_length, observation_space):\n",
    "        \"\"\"Cria um Memory Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        max_length: int\n",
    "            Tamanho máximo do Memory Buffer.\n",
    "        observation_space: int\n",
    "            Tamanho do espaço de observação.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.actions = np.zeros((max_length), dtype=np.int32)\n",
    "        self.rewards = np.zeros((max_length), dtype=np.float32)\n",
    "        self.next_states = np.zeros((max_length, observation_space), dtype=np.float32)\n",
    "        self.dones = np.zeros((max_length), dtype=np.float32)\n",
    "        self.logp = np.zeros((max_length), dtype=np.float32)\n",
    "\n",
    "    def update(self, states, actions, rewards, next_states, dones, logp):\n",
    "        \"\"\"Adiciona uma experiência ao Memory Buffer.\n",
    "\n",
    "        Parâmetros\n",
    "        ----------\n",
    "        state: np.array\n",
    "            Estado da transição.\n",
    "        action: int\n",
    "            Ação tomada.\n",
    "        reward: float\n",
    "            Recompensa recebida.\n",
    "        state: np.array\n",
    "            Estado seguinte.\n",
    "        done: int\n",
    "            Flag indicando se o episódio acabou.\n",
    "        logp: float\n",
    "            Log da probabilidade de acordo com a política.\n",
    "        \"\"\"\n",
    "        self.states[self.length] = states\n",
    "        self.actions[self.length] = actions\n",
    "        self.rewards[self.length] = rewards\n",
    "        self.next_states[self.length] = next_states\n",
    "        self.dones[self.length] = dones\n",
    "        self.logp[self.length] = logp\n",
    "        self.length += 1\n",
    "\n",
    "    def get_batch(self):\n",
    "        \"\"\"Retorna um batch de experiências.\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            Tamanho do batch de experiências.\n",
    "\n",
    "        Retorna\n",
    "        -------\n",
    "        states: np.array\n",
    "            Batch de estados.\n",
    "        actions: np.array\n",
    "            Batch de ações.\n",
    "        rewards: np.array\n",
    "            Batch de recompensas.\n",
    "        next_states: np.array\n",
    "            Batch de estados seguintes.\n",
    "        dones: np.array\n",
    "            Batch de flags indicando se o episódio acabou.\n",
    "        logp: np.array\n",
    "            Batch do log da probabilidade de acordo com a política.\n",
    "        \"\"\"\n",
    "        self.length = 0\n",
    "\n",
    "        return (self.states, self.actions, self.rewards, self.next_states, self.dones, self.logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, observation_space, action_space, lr=7e-4, gamma=0.99, lam=0.95,\n",
    "                 vf_coef=0.5, entropy_coef=0.005, clip_param=0.2, epochs=10, memory_len=16):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.vf_coef = vf_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.clip_param = clip_param\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.memory_len = memory_len\n",
    "        self.memory = MemoryBuffer(memory_len, observation_space.shape[0])\n",
    "\n",
    "        self.actorcritic = ActorCritic(observation_space.shape[0], action_space.n).to(self.device)\n",
    "        self.actorcritic_optimizer = optim.Adam(self.actorcritic.parameters(), lr=lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.FloatTensor(state).to(self.device).unsqueeze(0)\n",
    "        probs, v = self.actorcritic.forward(state)\n",
    "        action = probs.sample()\n",
    "        log_prob = probs.log_prob(action)\n",
    "        return action.cpu().detach().item(), log_prob.detach().cpu().numpy()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done, logp):\n",
    "        self.memory.update(state, action, reward, next_state, done, logp)\n",
    "\n",
    "    def compute_gae(self, rewards, dones, v, v2):\n",
    "        T = len(rewards)\n",
    "\n",
    "        returns = torch.zeros_like(rewards)\n",
    "        gaes = torch.zeros_like(rewards)\n",
    "        \n",
    "        future_gae = torch.tensor(0.0, dtype=rewards.dtype)\n",
    "        next_return = torch.tensor(v2[-1], dtype=rewards.dtype)\n",
    "\n",
    "        not_dones = 1 - dones\n",
    "        deltas = rewards + not_dones * self.gamma * v2 - v\n",
    "\n",
    "        for t in reversed(range(T)):\n",
    "            returns[t] = next_return = rewards[t] + self.gamma * not_dones[t] * next_return\n",
    "            gaes[t] = future_gae = deltas[t] + self.gamma * self.lam * not_dones[t] * future_gae\n",
    "\n",
    "        gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8) # Normalização\n",
    "\n",
    "        return gaes, returns\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.length < self.memory_len:\n",
    "            return\n",
    "\n",
    "        (states, actions, rewards, next_states, dones, old_logp) = self.memory.get_batch()\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.FloatTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(-1).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(-1).to(self.device)\n",
    "        old_logp = torch.FloatTensor(old_logp).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, v = self.actorcritic.forward(states)\n",
    "            _, v2 = self.actorcritic.forward(next_states)\n",
    "        \n",
    "        advantages, returns = self.compute_gae(rewards, dones, v, v2)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            probs, v = self.actorcritic.forward(states)\n",
    "\n",
    "            new_logp = probs.log_prob(actions)\n",
    "\n",
    "            #Equações principais do algoritmo\n",
    "            ratio = (new_logp.unsqueeze(-1) - old_logp.unsqueeze(-1)).exp() \n",
    "            surr1 = ratio * advantages.detach()\n",
    "            surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * advantages.detach()\n",
    "\n",
    "            entropy = probs.entropy().mean()\n",
    "\n",
    "            policy_loss =   - torch.min(surr1,surr2).mean()\n",
    "            value_loss =    self.vf_coef * F.mse_loss(v, returns.detach())\n",
    "            entropy_loss = -self.entropy_coef * entropy\n",
    "\n",
    "            self.actorcritic_optimizer.zero_grad()\n",
    "            (policy_loss + entropy_loss + value_loss).backward()\n",
    "            self.actorcritic_optimizer.step()\n",
    "\n",
    "        return policy_loss + entropy_loss + value_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import deque\n",
    "\n",
    "def train(agent, env, total_timesteps):\n",
    "    total_reward = 0\n",
    "    episode_returns = deque(maxlen=20)\n",
    "    avg_returns = []\n",
    "\n",
    "    state = env.reset()\n",
    "    timestep = 0\n",
    "    episode = 0\n",
    "\n",
    "    while timestep < total_timesteps:\n",
    "        action, log_prob = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done, log_prob)\n",
    "        loss = agent.train()\n",
    "        timestep += 1\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            episode_returns.append(total_reward)\n",
    "            episode += 1\n",
    "            next_state = env.reset()\n",
    "\n",
    "        if episode_returns:\n",
    "            avg_returns.append(np.mean(episode_returns))\n",
    "\n",
    "        total_reward *= 1 - done\n",
    "        state = next_state\n",
    "\n",
    "        ratio = math.ceil(100 * timestep / total_timesteps)\n",
    "\n",
    "        avg_return = avg_returns[-1] if avg_returns else np.nan\n",
    "        \n",
    "        print(f\"\\r[{ratio:3d}%] timestep = {timestep}/{total_timesteps}, episode = {episode:3d}, avg_return = {avg_return:10.4f}\", end=\"\")\n",
    "\n",
    "    return avg_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[100%] timestep = 75000/75000, episode = 295, avg_return =   256.9000"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "agente = PPO(env.observation_space, env.action_space)\n",
    "returns = train(agente, env, 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-25T01:15:37.844050</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.2875 248.518125 \nL 375.2875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m557d0891ea\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(45.324432 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"89.094535\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10000 -->\n      <g transform=\"translate(73.188285 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.683389\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20000 -->\n      <g transform=\"translate(113.777139 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.272243\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30000 -->\n      <g transform=\"translate(154.365993 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"210.861096\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40000 -->\n      <g transform=\"translate(194.954846 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.44995\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50000 -->\n      <g transform=\"translate(235.5437 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"292.038803\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60000 -->\n      <g transform=\"translate(276.132553 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"332.627657\" xlink:href=\"#m557d0891ea\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 70000 -->\n      <g transform=\"translate(316.721407 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m513c0fc6b9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m513c0fc6b9\" y=\"219.432996\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 223.232214)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m513c0fc6b9\" y=\"176.91816\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 180.717379)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m513c0fc6b9\" y=\"134.403325\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 138.202543)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m513c0fc6b9\" y=\"91.888489\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 95.687708)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m513c0fc6b9\" y=\"49.373654\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 53.172873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p11aadee833)\" d=\"M 48.505682 213.906067 \nL 48.538153 213.906067 \nL 48.651802 214.756364 \nL 48.659919 214.756364 \nL 48.704567 212.063757 \nL 48.773568 212.736909 \nL 48.814157 212.630622 \nL 48.818216 213.05577 \nL 48.870982 213.05577 \nL 48.903453 213.05577 \nL 49.017101 212.630622 \nL 49.065808 212.630622 \nL 49.134809 211.355177 \nL 49.179457 211.82284 \nL 49.272811 211.82284 \nL 49.390519 211.284319 \nL 49.621875 211.224362 \nL 49.666523 210.656719 \nL 49.731465 210.930028 \nL 49.877585 210.930028 \nL 49.958763 210.079732 \nL 49.991234 210.129749 \nL 50.238826 210.129749 \nL 50.352475 209.016861 \nL 50.608184 208.910574 \nL 50.673127 209.229435 \nL 50.721833 209.123148 \nL 50.819246 209.101891 \nL 50.932895 208.889316 \nL 51.164252 208.889316 \nL 51.277901 208.442911 \nL 51.342843 208.442911 \nL 51.444315 207.86896 \nL 51.456491 208.060277 \nL 51.602611 208.017762 \nL 51.724378 208.783029 \nL 51.736555 208.783029 \nL 51.833968 208.591713 \nL 51.838027 209.18692 \nL 51.988205 209.18692 \nL 52.093736 208.804287 \nL 52.207385 209.718356 \nL 52.288563 209.718356 \nL 52.402212 209.208178 \nL 52.637627 209.208178 \nL 52.751276 207.996505 \nL 52.982632 207.890218 \nL 53.096281 207.720158 \nL 53.197753 207.720158 \nL 53.311402 206.976149 \nL 53.701055 206.976149 \nL 53.814704 204.850407 \nL 54.180004 204.892922 \nL 54.293652 204.574061 \nL 54.77666 204.574061 \nL 54.890308 201.661794 \nL 55.113547 201.661794 \nL 55.227196 200.21629 \nL 55.312433 200.21629 \nL 55.426081 199.791142 \nL 55.43014 199.791142 \nL 55.543789 199.259706 \nL 55.637143 199.259706 \nL 55.730498 199.004617 \nL 55.750792 199.025875 \nL 56.347448 199.132162 \nL 56.461097 197.155222 \nL 56.505745 197.155222 \nL 56.619394 197.346539 \nL 56.720866 197.346539 \nL 56.834515 196.751331 \nL 57.167343 196.751331 \nL 57.280992 195.709717 \nL 57.792412 195.709717 \nL 57.90606 192.924996 \nL 58.060298 192.924996 \nL 58.173947 191.73458 \nL 58.336302 191.73458 \nL 58.449951 191.394462 \nL 58.506775 191.394462 \nL 58.620424 191.628293 \nL 58.669131 191.628293 \nL 58.78278 193.413916 \nL 59.050666 193.413916 \nL 59.164315 192.669907 \nL 60.085682 192.691164 \nL 60.199331 191.628293 \nL 60.495629 191.628293 \nL 60.609278 191.24566 \nL 60.877164 191.288174 \nL 60.990813 190.905541 \nL 61.538763 190.905541 \nL 61.652411 187.844473 \nL 61.818826 187.844473 \nL 61.932475 187.057948 \nL 62.508836 187.057948 \nL 62.622485 183.933108 \nL 63.154199 183.933108 \nL 63.267848 181.254673 \nL 63.576323 181.254673 \nL 63.689972 181.573535 \nL 63.994388 181.573535 \nL 64.108037 180.21306 \nL 64.712811 180.21306 \nL 64.82646 177.57714 \nL 65.203936 177.57714 \nL 65.317585 177.343308 \nL 65.548941 177.343308 \nL 65.66259 178.81007 \nL 66.153715 178.873843 \nL 66.267364 177.598397 \nL 66.839667 177.57714 \nL 66.953316 175.791517 \nL 67.135966 175.791517 \nL 67.249614 175.090022 \nL 67.326733 175.090022 \nL 67.440382 176.089121 \nL 67.533736 176.089121 \nL 67.647385 176.237923 \nL 67.943684 176.237923 \nL 68.057333 178.278635 \nL 68.187217 178.278635 \nL 68.300866 179.150189 \nL 68.564693 179.150189 \nL 68.678342 178.172348 \nL 68.787932 178.172348 \nL 68.901581 178.002288 \nL 69.181644 178.002288 \nL 69.295293 179.405278 \nL 69.437354 179.405278 \nL 69.551002 179.532822 \nL 69.92442 179.532822 \nL 70.038069 180.595693 \nL 70.176071 180.595693 \nL 70.28972 182.657663 \nL 70.756491 182.657663 \nL 70.87014 181.828624 \nL 71.276029 181.828624 \nL 71.389677 181.297188 \nL 71.763095 181.297188 \nL 71.876744 182.508861 \nL 72.116218 182.508861 \nL 72.229867 183.231613 \nL 72.826523 183.231613 \nL 72.940172 181.318446 \nL 73.147175 181.318446 \nL 73.260824 180.978327 \nL 73.796596 180.978327 \nL 73.910245 179.405278 \nL 75.071086 179.405278 \nL 75.184735 173.644518 \nL 75.610918 173.644518 \nL 75.724567 173.495716 \nL 76.978763 173.495716 \nL 77.092411 167.883758 \nL 77.697185 167.883758 \nL 77.810834 165.120293 \nL 78.350666 165.120293 \nL 78.464315 162.781977 \nL 79.487154 162.781977 \nL 79.600803 158.9769 \nL 80.355755 158.9769 \nL 80.469404 155.703257 \nL 81.877837 155.703257 \nL 81.991486 149.708665 \nL 83.90728 149.708665 \nL 84.020929 140.249115 \nL 84.654115 140.249115 \nL 84.767764 138.399719 \nL 85.202064 138.399719 \nL 85.315713 136.869185 \nL 85.624188 136.869185 \nL 85.737837 137.209304 \nL 85.83525 137.209304 \nL 85.948899 137.421878 \nL 86.245198 137.421878 \nL 86.358847 138.31469 \nL 86.707911 138.31469 \nL 86.82156 138.612293 \nL 87.332979 138.612293 \nL 87.446628 137.889541 \nL 88.047343 137.889541 \nL 88.160992 135.997631 \nL 89.342127 136.103918 \nL 89.455776 134.615899 \nL 90.190434 134.615899 \nL 90.304083 133.574285 \nL 92.219877 133.574285 \nL 92.333526 129.620406 \nL 92.942359 129.620406 \nL 93.056008 128.663822 \nL 93.368542 128.663822 \nL 93.48219 133.595543 \nL 93.798784 133.595543 \nL 93.912432 135.104819 \nL 94.553736 135.104819 \nL 94.667385 134.573384 \nL 96.433 134.615899 \nL 96.546649 135.232364 \nL 97.070245 135.232364 \nL 97.183894 139.866481 \nL 97.679078 139.866481 \nL 97.792727 147.306577 \nL 98.287911 147.306577 \nL 98.40156 148.029329 \nL 98.937332 148.029329 \nL 99.050981 147.497894 \nL 99.830287 147.497894 \nL 99.943936 145.032034 \nL 100.707006 145.032034 \nL 100.820655 141.545817 \nL 101.831318 141.545817 \nL 101.944966 137.804512 \nL 103.86076 137.804512 \nL 103.974409 129.599148 \nL 105.890203 129.599148 \nL 106.003852 122.244082 \nL 107.919646 122.244082 \nL 108.033294 115.356678 \nL 109.319961 115.356678 \nL 109.372727 111.63663 \nL 109.421433 118.736608 \nL 109.425492 118.736608 \nL 109.457963 118.736608 \nL 109.571612 129.152743 \nL 111.487406 129.152743 \nL 111.601055 122.307854 \nL 113.516849 122.307854 \nL 113.630497 113.911174 \nL 115.546291 113.911174 \nL 115.65994 105.535751 \nL 117.575734 105.535751 \nL 117.689383 98.860922 \nL 119.605177 98.860922 \nL 119.718825 94.141776 \nL 121.634619 94.141776 \nL 121.748268 87.445689 \nL 123.664062 87.445689 \nL 123.777711 80.154395 \nL 124.646312 80.154395 \nL 124.759961 78.198712 \nL 125.888331 78.198712 \nL 126.00198 74.882555 \nL 127.917774 74.882555 \nL 128.031423 67.655033 \nL 129.947217 67.655033 \nL 130.060865 61.702956 \nL 131.976659 61.702956 \nL 132.090308 55.66585 \nL 134.006102 55.66585 \nL 134.119751 50.925445 \nL 142.123873 50.925445 \nL 142.237521 47.630546 \nL 143.51607 47.630546 \nL 143.629719 40.615598 \nL 144.169551 40.615598 \nL 144.2832 37.426985 \nL 146.198994 37.426985 \nL 146.312642 27.01085 \nL 158.233589 27.01085 \nL 158.347237 27.75486 \nL 159.946438 27.75486 \nL 160.060087 29.412939 \nL 160.786627 29.412939 \nL 160.900276 30.156948 \nL 161.630876 30.156948 \nL 161.744524 32.240175 \nL 162.674009 32.240175 \nL 162.787658 37.405728 \nL 172.585807 37.405728 \nL 172.699456 38.638658 \nL 173.470644 38.638658 \nL 173.584293 44.63325 \nL 174.54219 44.63325 \nL 174.655839 49.65 \nL 175.836974 49.65 \nL 175.950623 50.160178 \nL 177.099288 50.160178 \nL 177.212937 46.971566 \nL 180.869992 46.971566 \nL 180.983641 48.480842 \nL 182.530076 48.480842 \nL 182.643725 50.415267 \nL 183.71933 50.415267 \nL 183.832979 54.815553 \nL 184.794934 54.815553 \nL 184.908583 59.811046 \nL 186.755376 59.811046 \nL 186.869025 60.172422 \nL 188.265281 60.172422 \nL 188.37893 62.149362 \nL 190.294724 62.149362 \nL 190.408373 60.491283 \nL 192.324167 60.491283 \nL 192.437816 54.26286 \nL 194.353609 54.26286 \nL 194.467258 48.055694 \nL 196.383052 48.055694 \nL 196.496701 42.890141 \nL 204.025933 42.890141 \nL 204.139582 45.377259 \nL 205.377542 45.377259 \nL 205.491191 47.694318 \nL 207.155334 47.694318 \nL 207.268983 43.017686 \nL 208.778888 43.017686 \nL 208.892537 40.126677 \nL 210.292852 40.126677 \nL 210.406501 38.978777 \nL 212.322295 38.978777 \nL 212.435944 34.961125 \nL 216.38118 34.961125 \nL 216.494829 33.451848 \nL 218.410623 33.451848 \nL 218.524272 31.517423 \nL 220.440066 31.517423 \nL 220.553714 27.117138 \nL 222.469508 27.117138 \nL 222.583157 22.121644 \nL 224.498951 22.121644 \nL 224.6126 21.760268 \nL 226.528394 21.760268 \nL 226.642042 19.039319 \nL 232.239245 19.039319 \nL 232.352894 21.016259 \nL 233.391969 21.016259 \nL 233.505618 25.607861 \nL 234.727342 25.607861 \nL 234.840991 29.242879 \nL 235.453883 29.242879 \nL 235.567531 36.06651 \nL 235.932831 36.06651 \nL 236.04648 44.186844 \nL 236.456427 44.186844 \nL 236.570076 49.586228 \nL 237.243851 49.586228 \nL 237.369676 61.660441 \nL 237.714682 61.660441 \nL 237.82833 67.888865 \nL 238.404692 67.888865 \nL 238.518341 72.20412 \nL 239.947069 72.20412 \nL 240.060717 74.755011 \nL 241.132263 74.755011 \nL 241.245912 79.176553 \nL 242.23628 79.176553 \nL 242.349929 84.023245 \nL 243.445828 84.023245 \nL 243.559477 88.317243 \nL 244.497079 88.317243 \nL 244.610728 93.440281 \nL 245.824335 93.440281 \nL 245.937983 97.117814 \nL 247.435712 97.117814 \nL 247.549361 99.307328 \nL 251.462126 99.307328 \nL 251.575775 99.477387 \nL 255.521012 99.477387 \nL 255.634661 97.500448 \nL 257.550454 97.500448 \nL 257.664103 92.908845 \nL 259.579897 92.908845 \nL 259.693546 89.273827 \nL 261.60934 89.273827 \nL 261.722989 82.450196 \nL 263.638782 82.450196 \nL 263.752431 74.329862 \nL 265.668225 74.329862 \nL 265.781874 66.44336 \nL 267.486606 66.44336 \nL 267.600255 61.043976 \nL 269.07363 61.043976 \nL 269.187279 52.923643 \nL 270.526711 52.923643 \nL 270.64036 47.588031 \nL 272.0975 47.588031 \nL 272.211148 42.975171 \nL 273.895586 42.975171 \nL 274.009235 41.635954 \nL 275.925028 41.635954 \nL 276.038677 37.214411 \nL 277.954471 37.214411 \nL 278.06812 32.36772 \nL 279.983914 32.36772 \nL 280.097563 28.073721 \nL 282.013356 28.073721 \nL 282.127005 22.950684 \nL 284.042799 22.950684 \nL 284.156448 19.27315 \nL 286.072242 19.27315 \nL 286.185891 17.083636 \nL 289.583178 17.083636 \nL 289.696826 19.783328 \nL 290.788667 19.783328 \nL 290.902315 24.098584 \nL 292.16057 24.098584 \nL 292.274219 27.542286 \nL 293.897773 27.542286 \nL 294.011422 29.07282 \nL 304.044986 29.07282 \nL 304.158635 27.967434 \nL 305.818719 27.967434 \nL 305.932368 26.989593 \nL 307.409802 26.989593 \nL 307.523451 26.266841 \nL 311.014092 26.245583 \nL 311.127741 25.033911 \nL 314.679266 25.033911 \nL 314.792915 27.09588 \nL 316.022757 27.09588 \nL 316.136406 30.688384 \nL 317.601663 30.688384 \nL 317.715312 33.047957 \nL 321.266837 33.047957 \nL 321.380486 35.109927 \nL 323.154218 35.109927 \nL 323.267867 35.853936 \nL 325.183661 35.853936 \nL 325.29731 32.984185 \nL 327.213104 32.984185 \nL 327.326753 28.668929 \nL 329.242547 28.668929 \nL 329.356195 25.225227 \nL 331.271989 25.225227 \nL 331.385638 23.694693 \nL 340.542483 23.694693 \nL 340.656132 28.286295 \nL 341.325848 28.286295 \nL 341.439497 33.473105 \nL 342.190391 33.473105 \nL 342.30404 37.278183 \nL 343.201053 37.278183 \nL 343.314702 40.232964 \nL 344.073714 40.232964 \nL 344.187362 46.291328 \nL 344.81649 46.291328 \nL 344.930138 53.02993 \nL 345.514618 53.02993 \nL 345.628267 57.940393 \nL 346.139686 57.940393 \nL 346.253335 61.702956 \nL 346.906816 61.702956 \nL 347.020464 65.95444 \nL 347.572473 65.95444 \nL 347.686122 73.096932 \nL 348.213777 73.096932 \nL 348.327425 78.304999 \nL 348.940317 78.304999 \nL 349.053966 84.384621 \nL 349.764271 84.384621 \nL 349.87792 90.698074 \nL 350.588225 90.698074 \nL 350.701873 97.011527 \nL 351.363472 97.011527 \nL 351.477121 103.580069 \nL 352.126542 103.580069 \nL 352.240191 110.212383 \nL 352.869318 110.212383 \nL 352.869318 110.212383 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p11aadee833\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(returns, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O agente demonstra consegue solocuinar o ambiente. Porém acaba desaprendendo, para solucionar isso é possível fazer uma otimização nos hiper-parâmetros. É possível também implementar algum tipo de parada antecipada."
   ]
  }
 ]
}